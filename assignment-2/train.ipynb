{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beba476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs import GymEnv\n",
    "import gym_chess\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e863f25",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"No conversion tool could be found with the gym space <class 'NoneType'>. You can register your own with `torchrl.envs.libs.register_gym_spec_conversion.`\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m chess_env = gym.make(\u001b[33m\"\u001b[39m\u001b[33mChess-v0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m env = \u001b[43mGymEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mChess-v0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/cpp/Artificial-Intelligence/assignment-2/.venv/lib/python3.12/site-packages/torchrl/envs/libs/gym.py:779\u001b[39m, in \u001b[36m_GymAsyncMeta.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m     instance: GymWrapper = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m     \u001b[38;5;66;03m# before gym 0.22, there was no final_observation\u001b[39;00m\n\u001b[32m    782\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m instance._is_batched:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/cpp/Artificial-Intelligence/assignment-2/.venv/lib/python3.12/site-packages/torchrl/envs/common.py:238\u001b[39m, in \u001b[36m_EnvPostInit.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    236\u001b[39m auto_reset = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mauto_reset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    237\u001b[39m auto_reset_replace = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mauto_reset_replace\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m instance: EnvBase = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m instance.\u001b[34m__dict__\u001b[39m:\n\u001b[32m    240\u001b[39m     instance._cache = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/cpp/Artificial-Intelligence/assignment-2/.venv/lib/python3.12/site-packages/torchrl/envs/libs/gym.py:1612\u001b[39m, in \u001b[36mGymEnv.__init__\u001b[39m\u001b[34m(self, env_name, **kwargs)\u001b[39m\n\u001b[32m   1610\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33menv_name\u001b[39m\u001b[33m\"\u001b[39m] = env_name\n\u001b[32m   1611\u001b[39m \u001b[38;5;28mself\u001b[39m._set_gym_args(kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1612\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/cpp/Artificial-Intelligence/assignment-2/.venv/lib/python3.12/site-packages/torchrl/envs/libs/gym.py:1003\u001b[39m, in \u001b[36mGymWrapper.__init__\u001b[39m\u001b[34m(self, env, categorical_action_encoding, **kwargs)\u001b[39m\n\u001b[32m   1001\u001b[39m         \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(**kwargs)\n\u001b[32m   1002\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1003\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28mself\u001b[39m._post_init()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/cpp/Artificial-Intelligence/assignment-2/.venv/lib/python3.12/site-packages/torchrl/envs/common.py:3698\u001b[39m, in \u001b[36m_EnvWrapper.__init__\u001b[39m\u001b[34m(self, device, batch_size, allow_done_after_reset, spec_locked, *args, **kwargs)\u001b[39m\n\u001b[32m   3696\u001b[39m \u001b[38;5;28mself\u001b[39m._convert_actions_to_numpy = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mconvert_actions_to_numpy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   3697\u001b[39m \u001b[38;5;28mself\u001b[39m._env = \u001b[38;5;28mself\u001b[39m._build_env(**kwargs)  \u001b[38;5;66;03m# writes the self._env attribute\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3698\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_specs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_env\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# writes the self._env attribute\u001b[39;00m\n\u001b[32m   3699\u001b[39m \u001b[38;5;28mself\u001b[39m.is_closed = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3700\u001b[39m \u001b[38;5;28mself\u001b[39m._init_env()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/cpp/Artificial-Intelligence/assignment-2/.venv/lib/python3.12/site-packages/torchrl/envs/libs/gym.py:1237\u001b[39m, in \u001b[36mGymWrapper._make_specs\u001b[39m\u001b[34m(self, env, batch_size)\u001b[39m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_specs\u001b[39m(\u001b[38;5;28mself\u001b[39m, env: \u001b[33m\"\u001b[39m\u001b[33mgym.Env\u001b[39m\u001b[33m\"\u001b[39m, batch_size=\u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;66;03m# If batch_size is provided, we se it to tell what batch size must be used\u001b[39;00m\n\u001b[32m   1235\u001b[39m     \u001b[38;5;66;03m# instead of self.batch_size\u001b[39;00m\n\u001b[32m   1236\u001b[39m     cur_batch_size = \u001b[38;5;28mself\u001b[39m.batch_size \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch.Size([])\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m     action_spec = \u001b[43m_gym_to_torchrl_spec_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_action_encoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_categorical_action_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1242\u001b[39m     observation_spec = _gym_to_torchrl_spec_transform(\n\u001b[32m   1243\u001b[39m         env.observation_space,\n\u001b[32m   1244\u001b[39m         device=\u001b[38;5;28mself\u001b[39m.device,\n\u001b[32m   1245\u001b[39m         categorical_action_encoding=\u001b[38;5;28mself\u001b[39m._categorical_action_encoding,\n\u001b[32m   1246\u001b[39m     )\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation_spec, Composite):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/cpp/Artificial-Intelligence/assignment-2/.venv/lib/python3.12/site-packages/torchrl/envs/libs/gym.py:345\u001b[39m, in \u001b[36m_gym_to_torchrl_spec_transform\u001b[39m\u001b[34m(spec, dtype, device, categorical_action_encoding, remap_state_to_observation, batch_size)\u001b[39m\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _gym_to_torchrl_spec_transform(\n\u001b[32m    336\u001b[39m         spec,\n\u001b[32m    337\u001b[39m         dtype=dtype,\n\u001b[32m   (...)\u001b[39m\u001b[32m    341\u001b[39m         batch_size=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    342\u001b[39m     ).expand(batch_size)\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# Get the conversion function from the registry\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m conversion_func = \u001b[43m_conversion_registry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# Call the conversion function with the provided arguments\u001b[39;00m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m conversion_func(\n\u001b[32m    348\u001b[39m     spec,\n\u001b[32m    349\u001b[39m     dtype=dtype,\n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m     batch_size=batch_size,\n\u001b[32m    354\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/cpp/Artificial-Intelligence/assignment-2/.venv/lib/python3.12/site-packages/torchrl/envs/libs/gym.py:261\u001b[39m, in \u001b[36m_ConversionRegistry.__getitem__\u001b[39m\u001b[34m(self, cls)\u001b[39m\n\u001b[32m    259\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[parents[p]]\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    262\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo conversion tool could be found with the gym space \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    263\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou can register your own with `torchrl.envs.libs.register_gym_spec_conversion.`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    264\u001b[39m         )\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"No conversion tool could be found with the gym space <class 'NoneType'>. You can register your own with `torchrl.envs.libs.register_gym_spec_conversion.`\""
     ]
    }
   ],
   "source": [
    "chess_env = gym.make(\"Chess-v0\")\n",
    "env = GymEnv(\"Chess-v0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
